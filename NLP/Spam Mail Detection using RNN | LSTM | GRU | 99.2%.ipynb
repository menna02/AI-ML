{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6651650,"sourceType":"datasetVersion","datasetId":3839058}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mennatullaheisawy/spam-mail-detection-using-rnn-lstm-gru-99-2?scriptVersionId=191789892\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# 1. Introduction\nIn this project, we will build and compare different Recurrent Neural Network (RNN) architectures, including LSTM (Long Short-Term Memory) and GRU (Gated Recurrent Units), to classify emails as spam or ham. The dataset used for this project contains SMS messages labeled as 'spam' or 'ham'.","metadata":{}},{"cell_type":"markdown","source":"# 2. Import Libraries\nIn this project, we will build and compare different Recurrent Neural Network (RNN) architectures, including LSTM (Long Short-Term Memory) and GRU (Gated Recurrent Units), to classify emails as spam or ham. The dataset used for this project contains SMS messages labeled as 'spam' or 'ham'.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU, Dense, Dropout\n\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-09T13:13:52.567988Z","iopub.execute_input":"2024-08-09T13:13:52.568419Z","iopub.status.idle":"2024-08-09T13:13:52.577482Z","shell.execute_reply.started":"2024-08-09T13:13:52.568384Z","shell.execute_reply":"2024-08-09T13:13:52.576136Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"We begin by importing the necessary libraries for data processing, model building, and evaluation. Libraries like TensorFlow are used for building RNN models, while scikit-learn is used for preprocessing and evaluation.","metadata":{}},{"cell_type":"markdown","source":"**Educational Content**:\n\n**Tokenization**: This is the process of converting text into tokens, which are the smallest units of text (like words or characters). In neural networks, tokens are then converted into sequences that can be fed into the models.\n\n**RNNs, LSTM, and GRU**: RNNs are neural networks well-suited for sequential data like text. LSTMs and GRUs are variants of RNNs designed to mitigate the vanishing gradient problem, allowing them to capture longer-term dependencies.","metadata":{}},{"cell_type":"markdown","source":"# 2. Loading and Exploring the Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/spam-emails/spam.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T13:13:52.579995Z","iopub.execute_input":"2024-08-09T13:13:52.580611Z","iopub.status.idle":"2024-08-09T13:13:52.636349Z","shell.execute_reply.started":"2024-08-09T13:13:52.580567Z","shell.execute_reply":"2024-08-09T13:13:52.634741Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"  Category                                            Message\n0      ham  Go until jurong point, crazy.. Available only ...\n1      ham                      Ok lar... Joking wif u oni...\n2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3      ham  U dun say so early hor... U c already then say...\n4      ham  Nah I don't think he goes to usf, he lives aro...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We start by loading the dataset and displaying the first few rows to understand its structure.","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T13:13:52.638892Z","iopub.execute_input":"2024-08-09T13:13:52.639379Z","iopub.status.idle":"2024-08-09T13:13:52.654026Z","shell.execute_reply.started":"2024-08-09T13:13:52.639336Z","shell.execute_reply":"2024-08-09T13:13:52.652443Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5572 entries, 0 to 5571\nData columns (total 2 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   Category  5572 non-null   object\n 1   Message   5572 non-null   object\ndtypes: object(2)\nmemory usage: 87.2+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T13:13:52.656021Z","iopub.execute_input":"2024-08-09T13:13:52.657074Z","iopub.status.idle":"2024-08-09T13:13:52.68532Z","shell.execute_reply.started":"2024-08-09T13:13:52.657034Z","shell.execute_reply":"2024-08-09T13:13:52.684043Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"       Category                 Message\ncount      5572                    5572\nunique        2                    5157\ntop         ham  Sorry, I'll call later\nfreq       4825                      30","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5572</td>\n      <td>5572</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>2</td>\n      <td>5157</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>ham</td>\n      <td>Sorry, I'll call later</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>4825</td>\n      <td>30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Data Understanding**: \n\nThe dataset contains two columns: Category, which is the target variable (ham or spam), and Message, which contains the text data to be classified.","metadata":{}},{"cell_type":"markdown","source":"# 4. Data Cleaning and Preprocessing","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Checking for Duplicates","metadata":{}},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T13:13:52.688134Z","iopub.execute_input":"2024-08-09T13:13:52.689418Z","iopub.status.idle":"2024-08-09T13:13:52.706014Z","shell.execute_reply.started":"2024-08-09T13:13:52.689365Z","shell.execute_reply":"2024-08-09T13:13:52.704092Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"415"},"metadata":{}}]},{"cell_type":"markdown","source":"### 4.2 Removing Duplicates","metadata":{}},{"cell_type":"code","source":"df.drop_duplicates(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T13:13:52.707786Z","iopub.execute_input":"2024-08-09T13:13:52.708301Z","iopub.status.idle":"2024-08-09T13:13:52.719842Z","shell.execute_reply.started":"2024-08-09T13:13:52.708243Z","shell.execute_reply":"2024-08-09T13:13:52.718307Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### 4.3 Label Encoding","metadata":{}},{"cell_type":"code","source":"encoder = LabelEncoder()\ndf['Category'] = encoder.fit_transform(df['Category'])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T13:13:52.721584Z","iopub.execute_input":"2024-08-09T13:13:52.722017Z","iopub.status.idle":"2024-08-09T13:13:52.742817Z","shell.execute_reply.started":"2024-08-09T13:13:52.721977Z","shell.execute_reply":"2024-08-09T13:13:52.741442Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"   Category                                            Message\n0         0  Go until jurong point, crazy.. Available only ...\n1         0                      Ok lar... Joking wif u oni...\n2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n3         0  U dun say so early hor... U c already then say...\n4         0  Nah I don't think he goes to usf, he lives aro...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Here, we convert the categorical labels (ham and spam) into numeric form using Label Encoding. This step is necessary because most machine learning models work with numerical data.","metadata":{}},{"cell_type":"markdown","source":"**Educational Content**:\n\nLabel Encoding: It is a process of converting categorical data into a format that can be provided to ML algorithms to improve predictions. It assigns a unique number to each class.","metadata":{}},{"cell_type":"markdown","source":"# 5. Data Preparation for Model Training","metadata":{}},{"cell_type":"code","source":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(df['Message'])\nsequences = tokenizer.texts_to_sequences(df['Message'])\n\nmax_len = max([len(seq) for seq in sequences])\nX = pad_sequences(sequences, maxlen= max_len)\ny = df['Category']\n\nvocabs = len(tokenizer.word_index)+1","metadata":{"execution":{"iopub.status.busy":"2024-08-09T13:13:52.744335Z","iopub.execute_input":"2024-08-09T13:13:52.744794Z","iopub.status.idle":"2024-08-09T13:13:53.065136Z","shell.execute_reply.started":"2024-08-09T13:13:52.744749Z","shell.execute_reply":"2024-08-09T13:13:53.063838Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"In this step, we convert the text data into sequences of tokens and then pad them to ensure that all sequences have the same length. This preprocessing step is crucial for feeding text data into RNN models.\n","metadata":{}},{"cell_type":"markdown","source":"**Educational Content**\n\n**Padding**: Padding sequences ensures that all input sequences are of the same length, which is necessary for batch processing in neural networks.","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T13:13:53.066424Z","iopub.execute_input":"2024-08-09T13:13:53.066796Z","iopub.status.idle":"2024-08-09T13:13:53.076335Z","shell.execute_reply.started":"2024-08-09T13:13:53.066766Z","shell.execute_reply":"2024-08-09T13:13:53.07492Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# 6. Building and Training the Models","metadata":{}},{"cell_type":"markdown","source":"## Simple RNN Model","metadata":{}},{"cell_type":"code","source":"rnn_model= Sequential([\n    Embedding(vocabs, 64, input_length = max_len ),\n    SimpleRNN(128),\n    Dense(1, activation='sigmoid')\n])\n\nrnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-08-09T13:30:39.65025Z","iopub.execute_input":"2024-08-09T13:30:39.65074Z","iopub.status.idle":"2024-08-09T13:30:39.671862Z","shell.execute_reply.started":"2024-08-09T13:30:39.650694Z","shell.execute_reply":"2024-08-09T13:30:39.670432Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## LSTM Model","metadata":{}},{"cell_type":"code","source":"lstm_model= Sequential([\n    Embedding(vocabs, 64, input_length = max_len ),\n    LSTM(128),\n    Dropout(0.2),\n    Dense(1, activation='sigmoid')\n])\n\nlstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-08-09T13:30:43.367852Z","iopub.execute_input":"2024-08-09T13:30:43.368283Z","iopub.status.idle":"2024-08-09T13:30:43.393628Z","shell.execute_reply.started":"2024-08-09T13:30:43.368249Z","shell.execute_reply":"2024-08-09T13:30:43.392162Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## GRU Model","metadata":{}},{"cell_type":"code","source":"gru_model= Sequential([\n    Embedding(vocabs, 64, input_length = max_len ),\n    GRU(128),\n    Dropout(0.4),\n    Dense(1, activation='sigmoid')\n])\n\ngru_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-08-09T13:30:45.80361Z","iopub.execute_input":"2024-08-09T13:30:45.804055Z","iopub.status.idle":"2024-08-09T13:30:45.829997Z","shell.execute_reply.started":"2024-08-09T13:30:45.804021Z","shell.execute_reply":"2024-08-09T13:30:45.828581Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# 7. Model Evaluation","metadata":{}},{"cell_type":"markdown","source":"## Training and Testing the Models","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\nrnn_cb = EarlyStopping(patience=5, restore_best_weights=True)\nlstm_cb = EarlyStopping(patience=5, restore_best_weights=True)\ngru_cb = EarlyStopping(patience=5, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T13:30:48.516171Z","iopub.execute_input":"2024-08-09T13:30:48.516617Z","iopub.status.idle":"2024-08-09T13:30:48.523044Z","shell.execute_reply.started":"2024-08-09T13:30:48.516577Z","shell.execute_reply":"2024-08-09T13:30:48.521748Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"history_rnn = rnn_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=16, callbacks=rnn_cb)\nhistory_lstm = lstm_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=16, callbacks=lstm_cb)\nhistory_gru = gru_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=16, callbacks=gru_cb)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T13:30:59.650229Z","iopub.execute_input":"2024-08-09T13:30:59.651639Z","iopub.status.idle":"2024-08-09T13:44:08.858549Z","shell.execute_reply.started":"2024-08-09T13:30:59.651595Z","shell.execute_reply":"2024-08-09T13:44:08.857307Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 0.8651 - loss: 0.3688 - val_accuracy: 0.9767 - val_loss: 0.0858\nEpoch 2/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.9870 - loss: 0.0479 - val_accuracy: 0.9884 - val_loss: 0.0457\nEpoch 3/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - accuracy: 0.9977 - loss: 0.0087 - val_accuracy: 0.9903 - val_loss: 0.0416\nEpoch 4/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.9996 - loss: 0.0021 - val_accuracy: 0.9835 - val_loss: 0.0520\nEpoch 5/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - accuracy: 0.9999 - loss: 8.8069e-04 - val_accuracy: 0.9816 - val_loss: 0.0540\nEpoch 6/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - accuracy: 0.9997 - loss: 7.7973e-04 - val_accuracy: 0.9893 - val_loss: 0.0526\nEpoch 7/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 2.9623e-04 - val_accuracy: 0.9903 - val_loss: 0.0493\nEpoch 8/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 1.5846e-04 - val_accuracy: 0.9903 - val_loss: 0.0520\nEpoch 1/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 128ms/step - accuracy: 0.9195 - loss: 0.2815 - val_accuracy: 0.9806 - val_loss: 0.0673\nEpoch 2/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 125ms/step - accuracy: 0.9909 - loss: 0.0349 - val_accuracy: 0.9884 - val_loss: 0.0515\nEpoch 3/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 126ms/step - accuracy: 0.9981 - loss: 0.0093 - val_accuracy: 0.9884 - val_loss: 0.0521\nEpoch 4/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 125ms/step - accuracy: 0.9995 - loss: 0.0040 - val_accuracy: 0.9874 - val_loss: 0.0640\nEpoch 5/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 124ms/step - accuracy: 0.9978 - loss: 0.0162 - val_accuracy: 0.9835 - val_loss: 0.0598\nEpoch 6/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 124ms/step - accuracy: 0.9998 - loss: 0.0031 - val_accuracy: 0.9922 - val_loss: 0.0399\nEpoch 7/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 124ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.9903 - val_loss: 0.0533\nEpoch 8/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 125ms/step - accuracy: 0.9998 - loss: 9.8089e-04 - val_accuracy: 0.9903 - val_loss: 0.0554\nEpoch 9/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 3.3066e-04 - val_accuracy: 0.9884 - val_loss: 0.0588\nEpoch 10/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 7.9453e-04 - val_accuracy: 0.9903 - val_loss: 0.0626\nEpoch 1/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 150ms/step - accuracy: 0.8979 - loss: 0.2784 - val_accuracy: 0.9874 - val_loss: 0.0484\nEpoch 2/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 147ms/step - accuracy: 0.9941 - loss: 0.0238 - val_accuracy: 0.9777 - val_loss: 0.0965\nEpoch 3/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 148ms/step - accuracy: 0.9956 - loss: 0.0310 - val_accuracy: 0.9855 - val_loss: 0.0532\nEpoch 4/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 146ms/step - accuracy: 0.9990 - loss: 0.0047 - val_accuracy: 0.9903 - val_loss: 0.0430\nEpoch 5/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 146ms/step - accuracy: 0.9994 - loss: 0.0030 - val_accuracy: 0.9913 - val_loss: 0.0463\nEpoch 6/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 9.3063e-04 - val_accuracy: 0.9884 - val_loss: 0.0466\nEpoch 7/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 144ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 0.9874 - val_loss: 0.0544\nEpoch 8/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 145ms/step - accuracy: 0.9998 - loss: 3.9785e-04 - val_accuracy: 0.9874 - val_loss: 0.0542\nEpoch 9/10\n\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 2.1413e-04 - val_accuracy: 0.9874 - val_loss: 0.0591\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We train each model on the training data and evaluate their performance on the test data. The models are trained for 10 epochs with a batch size of 16.\n\n","metadata":{}},{"cell_type":"markdown","source":"**Educational Content**\n\nEpochs and Batch Size: An epoch is one complete pass through the entire training dataset. Batch size refers to the number of training examples utilized in one iteration.","metadata":{}},{"cell_type":"markdown","source":"### Performance Metrics","metadata":{}},{"cell_type":"code","source":"y_pred_rnn = rnn_model.predict(X_test)\ny_pred_lstm = lstm_model.predict(X_test)\ny_pred_gru = gru_model.predict(X_test)\n\nprint(\"RNN Model Accuracy: \", accuracy_score(y_test, y_pred_rnn.round()))\nprint(\"LSTM Model Accuracy: \", accuracy_score(y_test, y_pred_lstm.round()))\nprint(\"GRU Model Accuracy: \", accuracy_score(y_test, y_pred_gru.round()))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-09T13:44:15.896071Z","iopub.execute_input":"2024-08-09T13:44:15.896576Z","iopub.status.idle":"2024-08-09T13:44:21.806708Z","shell.execute_reply.started":"2024-08-09T13:44:15.896531Z","shell.execute_reply":"2024-08-09T13:44:21.805519Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step\nRNN Model Accuracy:  0.9903100775193798\nLSTM Model Accuracy:  0.9922480620155039\nGRU Model Accuracy:  0.9903100775193798\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Here, we predict the test data using the trained models and calculate the accuracy. The performance of each model is compared to identify the best model for this task.","metadata":{}},{"cell_type":"markdown","source":"### Confusion Matrix and Classification Report\n","metadata":{}},{"cell_type":"markdown","source":"#### 1. RNN","metadata":{}},{"cell_type":"code","source":"print(confusion_matrix(y_test, y_pred_rnn.round()))\nprint(classification_report(y_test, y_pred_rnn.round()))","metadata":{"execution":{"iopub.status.busy":"2024-08-09T13:45:12.769944Z","iopub.execute_input":"2024-08-09T13:45:12.770361Z","iopub.status.idle":"2024-08-09T13:45:12.792996Z","shell.execute_reply.started":"2024-08-09T13:45:12.770328Z","shell.execute_reply":"2024-08-09T13:45:12.791712Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"[[896   0]\n [ 10 126]]\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99       896\n           1       1.00      0.93      0.96       136\n\n    accuracy                           0.99      1032\n   macro avg       0.99      0.96      0.98      1032\nweighted avg       0.99      0.99      0.99      1032\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### 2. LSTM","metadata":{}},{"cell_type":"code","source":"print(confusion_matrix(y_test, y_pred_lstm.round()))\nprint(classification_report(y_test, y_pred_lstm.round()))","metadata":{"execution":{"iopub.status.busy":"2024-08-09T13:45:23.490689Z","iopub.execute_input":"2024-08-09T13:45:23.491792Z","iopub.status.idle":"2024-08-09T13:45:23.513763Z","shell.execute_reply.started":"2024-08-09T13:45:23.491736Z","shell.execute_reply":"2024-08-09T13:45:23.51258Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"[[893   3]\n [  5 131]]\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      1.00       896\n           1       0.98      0.96      0.97       136\n\n    accuracy                           0.99      1032\n   macro avg       0.99      0.98      0.98      1032\nweighted avg       0.99      0.99      0.99      1032\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### 3. GRU","metadata":{}},{"cell_type":"code","source":"print(confusion_matrix(y_test, y_pred_gru.round()))\nprint(classification_report(y_test, y_pred_gru.round()))","metadata":{"execution":{"iopub.status.busy":"2024-08-09T13:45:33.378227Z","iopub.execute_input":"2024-08-09T13:45:33.379666Z","iopub.status.idle":"2024-08-09T13:45:33.403881Z","shell.execute_reply.started":"2024-08-09T13:45:33.379616Z","shell.execute_reply":"2024-08-09T13:45:33.402506Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"[[893   3]\n [  7 129]]\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99       896\n           1       0.98      0.95      0.96       136\n\n    accuracy                           0.99      1032\n   macro avg       0.98      0.97      0.98      1032\nweighted avg       0.99      0.99      0.99      1032\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We evaluate the models using confusion matrices and classification reports, which provide more insights into the model performance by showing precision, recall, and F1-score.","metadata":{}},{"cell_type":"markdown","source":"# 8. Conclusion","metadata":{}},{"cell_type":"markdown","source":"In this notebook, we built and compared three different RNN-based models for spam detection: Simple RNN, LSTM, and GRU. Among these models, **[LSTM]** showed the highest accuracy with **[99%]**. It also had **[the best Precision and Recall Results]**.\n","metadata":{}}]}
