{"metadata":{"colab":{"authorship_tag":"ABX9TyPvYJdnwSJP/8U0xehKmJCk","provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mennatullaheisawy/titanic-binary-classification-with-lgbm-xgboost?scriptVersionId=191745621\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix","metadata":{"execution":{"iopub.execute_input":"2024-08-08T19:31:21.012501Z","iopub.status.busy":"2024-08-08T19:31:21.01215Z","iopub.status.idle":"2024-08-08T19:31:24.786278Z","shell.execute_reply":"2024-08-08T19:31:24.785375Z","shell.execute_reply.started":"2024-08-08T19:31:21.012459Z"},"executionInfo":{"elapsed":261,"status":"ok","timestamp":1711795190266,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"k2h-_YhuBjA0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import LabelEncoder\nsns.set(style='darkgrid')\n\nclass DataCleaningClass:\n    def data_info(self, data):\n        cols, dtype, nulls, duplicates, uniques = [], [], [], [], []\n\n        for col in data.columns:\n            cols.append(col)\n            dtype.append(data[col].dtype)\n            nulls.append(data[col].isnull().sum())\n            duplicates.append(data.duplicated().sum())\n            uniques.append(data[col].nunique())\n\n        df = pd.DataFrame(\n            {'Column': cols, 'DType': dtype, 'no of Nulls': nulls, 'no of Uniques': uniques, 'Duplicated rows': duplicates})\n        return df\n\n\n    # __data=[]\n    def split_data(self, data, categorical_threshold=10):\n        numerical_data = data.select_dtypes(include=['number'])\n        object_data = data.select_dtypes(include=['object'])\n        unique_data = data.nunique()\n        cat_cols = unique_data[unique_data <= categorical_threshold].index\n        cont_cols = unique_data[unique_data > categorical_threshold].index\n        return numerical_data, object_data, cat_cols, cont_cols\n\n    # numerical_data, object_data, cat_cols, cont_cols = split_data(data, 10)\n\n# NUMERICAL PLOTTING\n    def columns_histplot(self, data):\n        # data = numerical data\n        c = 3\n        r = math.ceil(len(data.columns)/c)\n        plt.figure(figsize=(20,5*r))\n        l = len(data.columns)\n        for i in range(l):\n            plt.subplot(r, c, i + 1)\n            sns.histplot(data[data.columns[i]], bins=10, kde=True)\n            plt.title(f'HistPlot of {data.columns[i]}', fontsize=14, color='darkblue')\n            plt.xticks(rotation=45)\n            plt.ylabel('Frequency')\n\n        plt.tight_layout()\n        plt.show()\n\n    def columns_boxplot(self, data):\n        # data = numerical_data\n        l = len(data.columns)\n        plt.figure(figsize=(20, 30))\n        for i in range(l):\n            plt.subplot(l, 1, i + 1)\n            sns.boxplot(x=data[data.columns[i]])\n            plt.title(f'BoxPlot of {data.columns[i]}', fontsize=22, color='darkblue')\n\n        plt.tight_layout()\n        plt.show()\n\n# CATEGORICAL PLOTTING\n    def columns_pie(self, data):\n        # data = data[cat_cols]\n        c = 3\n        r = math.ceil(len(data.columns) / c)\n        plt.figure(figsize=(100, 100))\n        l = len(data.columns)\n        for i in range(l):\n            plt.subplot(r, c, i + 1)\n            unique_values = data[data.columns[i]].unique()\n            label = unique_values if not pd.isnull(unique_values).any() else unique_values[:-1]\n            plt.pie(data[data.columns[i]].value_counts(normalize=True), autopct='%1.0f%%', labels=label,\n                    textprops={'fontsize': 48})\n            plt.title(f'Pie Chart of {data.columns[i]}', fontsize=64)\n        plt.tight_layout()\n        plt.show()\n\n        # CATEGORICAL PLOTTING WITH RESPECT TO CATEGORICAL TARGET\n    def columns_countplot(self, data, target_index=0.1):\n        # data = data[cat_cols]\n        # target_data = the data of the target column if it is categorical\n        c = 3\n        r = math.ceil(len(data.columns) / c)\n        plt.figure(figsize=(20, 5 * r))\n        l = len(data.columns)\n        for i in range(l):\n            plt.subplot(r, c, i + 1)\n            if (target_index == 0.1):\n                sns.countplot(x=data[data.columns[i]])\n                plt.title(f'CountPlot of {data.columns[i]}', fontsize=22, color='darkblue')\n            else:\n                if (target_index == i):\n                    continue\n                sns.countplot(x=data[data.columns[i]], hue=data[data.columns[target_index]])\n                plt.title(f'CountPlot of {data.columns[i]} with {data.columns[target_index]} as a hue ',\n                          fontsize=22,\n                          color='darkblue')\n            plt.xticks(rotation=45)\n\n        plt.tight_layout()\n        plt.show()\n\n\n# CATEGORICAL PLOTTING WITH RESPECT TO CONTINUOUS TARGET\n    def columns_barplot(self, data, target_data):\n        # data = data[cat_cols]\n        # target_data = the data of the target column if it is categorical\n        l = len(data.columns)\n        plt.figure(figsize=(10, 30))\n        for i in range(l):\n            plt.subplot(l, 1, i + 1)\n            sns.barplot(x=data.columns[i], y=target_data)\n            plt.title(f'BarPlot of {data.columns[i]} related to the {target_data.name}', fontsize=14, color='darkblue')\n\n        plt.tight_layout()\n        plt.show()\n\n# CATEGORICAL PLOTTING WITH RESPECT TO CATEGORICAL TARGET\n    def columns_countplot(self, data, target_index=0.1):\n        # data = data[cat_cols]\n        # target_data = the data of the target column if it is categorical\n        c = 3\n        r = math.ceil(len(data.columns) / c)\n        plt.figure(figsize=(20, 5 * r))\n        l = len(data.columns)\n        for i in range(l):\n            plt.subplot(r, c, i + 1)\n            if(target_index==0.1):\n                sns.countplot(x=data[data.columns[i]])\n                plt.title(f'CountPlot of {data.columns[i]}', fontsize=22, color='darkblue')\n            else:\n                if(target_index==i):\n                    continue\n                sns.countplot(x=data[data.columns[i]], hue=data[data.columns[target_index]])\n                plt.title(f'CountPlot of {data.columns[i]} with {data.columns[target_index]} as a hue ', fontsize=22,\n                      color='darkblue')\n            plt.xticks(rotation=45)\n\n        plt.tight_layout()\n        plt.show()\n\n# CONTINUOUS PLOTTING WITH RESPECT TO CONTINUOUS TARGET\n    def columns_scatterplot(self, data, target_data):\n        # data = data[cont_cols]\n        # target_data = the data of the target column if it is continuous\n        c = 3\n        r = math.ceil(len(data.columns)/c)\n        plt.figure(figsize=(20,5*r))\n        l = len(data.columns)\n        for i in range(l):\n            plt.subplot(r, c, i + 1)\n            sns.scatterplot(x = data[data.columns[i]], y =target_data)\n            plt.title(f'ScatterPlot of {data.columns[i]} with {target_data.name}', fontsize=22, color='darkblue')\n            plt.xticks(rotation=45)\n\n        plt.tight_layout()\n        plt.show()\n\n    def columns_lineplot(self, data, target_data):\n        # data = data[cont_cols]\n        # target_data = the data of the target column if it is continuous\n        l = len(data.columns)\n        plt.figure(figsize=(20, 30))\n        for i in range(l):\n            plt.subplot((l//2)+1, 2, i + 1)\n            sns.lineplot(x=data[data.columns[i]],y=target_data)\n            plt.title(f'Line Plot of {data.columns[i]} with {target_data.name}', fontsize=22, color='darkblue')\n\n        plt.tight_layout()\n        plt.show()\n\n\n\n\n# DATA CLEANING\n    def columns_fillna(self,data):\n        for col in data.columns:\n            if col in (data.select_dtypes(include=['number'])):\n                data[col] = data[col].fillna(data[col].median())\n            elif col in (data.select_dtypes(include=['object'])):\n                data[col] = data[col].fillna(data[col].mode()[0])\n\n        return data\n\n\n    def columns_outlier(self,data, drop_categorical_outliers=False):\n        # data = data\n        for col in data.columns:\n            if col in (data.select_dtypes(include=['number'])):\n                q1, q3 = data[col].quantile([0.25, 0.75])\n                iqr = q3 - q1\n                lower = q1 - 1.5 * iqr\n                upper = q3 + 1.5 * iqr\n                outlier = (data[col] < lower) | (data[col] > upper)\n                data = data[~outlier]\n\n            elif (col in data.select_dtypes(include=['object']) and drop_categorical_outliers==True):\n                for value in data[col].unique():\n                    value_len = len(data[data[col]==value])\n                    if value_len < len(data.columns):\n                        data = data.drop(data[data[col]==value].index, axis=0)\n\n            # data.reset_index(drop=True, inplace=True)\n        return data\n\n\n    def columns_transformation(self,data):\n        # data = numerical_data\n        skewed_data = data.skew()\n        right_skewed = skewed_data[skewed_data > 0.6]\n        left_skewed = skewed_data[skewed_data < (-0.5)]\n        for col in skewed_data.index:\n            if col in right_skewed.index:  # right skewed --> log transformer\n                tr = ColumnTransformer(transformers=[('lg', FunctionTransformer(np.log1p), [col])])\n                tr_type = 'Log'\n            elif col in left_skewed.index:  # left skewed --> square tranformer\n                tr = ColumnTransformer(transformers=[('sq', FunctionTransformer(np.square), [col])])\n                tr_type = 'Square'\n            else:\n                continue\n            plt.figure(figsize=(15, 6))\n            col_tr = pd.DataFrame(tr.fit_transform(data))\n            skew_before = data[col].skew()\n            skew_after = col_tr[0].skew()\n            plt.subplot(1, 2, 1)\n            plt.title(f\"Distribution of {col} before Transformation\", fontsize=15)\n            sns.histplot(data[col], kde=True, color=\"red\")\n\n            data[col] = col_tr[0]\n            plt.subplot(1, 2, 2)\n            plt.title(f\"Distribution of {col} after Transformation\", fontsize=15)\n            sns.histplot(data[col], bins=20, kde=True, legend=False)\n            plt.xlabel(col)\n            plt.show()\n            print(\n                f\"Skewness was {round(skew_before, 2)} before & now it is {round(skew_after, 2)} after {tr_type} transformation.\")\n\n        return data\n\n    def columns_lencoder(self,data):\n        # data = object_data\n        le = LabelEncoder()\n        for col in data.columns:\n            data[col] = le.fit_transform(data[col])\n        return data\n\n    def columns_drop(self,data, cols):\n        # data = data\n        # cols = list of columns you need to drop\n        # -- do not forget to call the split function\n        data = data.drop(columns = cols, axis=1)\n        # data = data.reset_index(drop=True)\n        return data\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %pip install dataprep xgboost lightgbm","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-08-08T19:32:05.668265Z","iopub.status.busy":"2024-08-08T19:32:05.667883Z","iopub.status.idle":"2024-08-08T19:32:51.973115Z","shell.execute_reply":"2024-08-08T19:32:51.971746Z","shell.execute_reply.started":"2024-08-08T19:32:05.668233Z"},"executionInfo":{"elapsed":10185,"status":"ok","timestamp":1711794578612,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"dXQNgeE_lNjY","outputId":"29c0b3af-5f1b-4ad0-f766-1e0a3e3f5dff","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from dataprep.datasets import load_dataset\nfrom dataprep.eda import create_report, plot, plot_correlation, plot_diff, plot_missing","metadata":{"execution":{"iopub.execute_input":"2024-08-08T19:33:19.999628Z","iopub.status.busy":"2024-08-08T19:33:19.999159Z","iopub.status.idle":"2024-08-08T19:33:21.50152Z","shell.execute_reply":"2024-08-08T19:33:21.500542Z","shell.execute_reply.started":"2024-08-08T19:33:19.999587Z"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1711794578612,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"cxaQhb7rlzmA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{"id":"kwCXS1Yx2JF7"}},{"cell_type":"code","source":"data = load_dataset('titanic')\ndata.head()","metadata":{"execution":{"iopub.execute_input":"2024-08-08T19:33:27.388651Z","iopub.status.busy":"2024-08-08T19:33:27.388025Z","iopub.status.idle":"2024-08-08T19:33:27.418033Z","shell.execute_reply":"2024-08-08T19:33:27.416976Z","shell.execute_reply.started":"2024-08-08T19:33:27.388615Z"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1711794578613,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"iAmQy1vqDyv5","outputId":"68835f0b-b940-4332-b1c8-cf073b76fa0b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using the **DataPrep** create_report method, we have the following Interpertations about this dataset.\n\n\n*   data shape: (12,891)\n*   3 numerical, 9 categorical\n*   no duplicated rows(because of the ID and Name columns)\n*   Age(19.9%), and Cabin(77.1), Embarked(0.2%) contain NaNs\n*   The target column is Survived ( Binary Classification )\n\nFrom the intital plots:\n\n\n*   The major label in the target column is 0, not survived (61%)\n*   The major category in pclass(55%), parch(76%), SibSp(68%) is 0\n*   The major in sex is male (64%)\n*   The major is embark is 's'\n*   Fare is right skewed and has outliers\n*   Age has outliers\n\nNotes:\n\n*   The strongest correlation is 0.41 between SibSp and Parch","metadata":{"id":"ePDy0lvgvH6G"}},{"cell_type":"code","source":"plot_missing(data)","metadata":{"execution":{"iopub.execute_input":"2024-08-08T19:29:09.251346Z","iopub.status.busy":"2024-08-08T19:29:09.25094Z","iopub.status.idle":"2024-08-08T19:29:09.671742Z","shell.execute_reply":"2024-08-08T19:29:09.670321Z","shell.execute_reply.started":"2024-08-08T19:29:09.251301Z"},"executionInfo":{"elapsed":47,"status":"ok","timestamp":1711794596761,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"BTYCFJ-Lv48Y","outputId":"f6680a8f-6ca0-4428-e0a1-430a2843e839","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot(data, 'PassengerId')","metadata":{"executionInfo":{"elapsed":4986,"status":"ok","timestamp":1711794601736,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"R31SBgG2wQkW","outputId":"7efbf6ee-37ab-4cbc-aaa1-d1a514de42f6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Initial Feature Selection:\n\n*   I will drop Passenger_ID, Name as they are uniformly distributed.\n*   and Cabin as it has 77.1% NaN values.\n*   Drop Ticket feature as it has 76.4 unique continous noninfo values\n","metadata":{"id":"zF6ey10Qw0Sj"}},{"cell_type":"code","source":"plot_missing(data, 'Survived')","metadata":{"executionInfo":{"elapsed":103,"status":"ok","timestamp":1711794613776,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"CmtTI6nlm3Fj","outputId":"a10887cf-458a-4703-e7be-30650788a2b7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot(data, 'Survived', 'Age')","metadata":{"executionInfo":{"elapsed":81,"status":"ok","timestamp":1711794613776,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"9yjuPBMavV2o","outputId":"c0db32e4-0b6c-4589-baab-374847450779"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* From the box plot between Age and Survived, the median in both of the classes is the same so I can replace NaNs with the median of the whole features","metadata":{"id":"nkh1WeoexS4H"}},{"cell_type":"code","source":"plot(data, 'Fare')","metadata":{"executionInfo":{"elapsed":62,"status":"ok","timestamp":1711794613776,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"T9NaPs6Ww_KX","outputId":"af7158fb-f387-4700-b317-8f4c8c99d945"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* This feature has a lot of outliers need to be removed","metadata":{"id":"gORdPYqsyqPO"}},{"cell_type":"code","source":"plot(data, 'Survived', 'Pclass')","metadata":{"executionInfo":{"elapsed":34,"status":"ok","timestamp":1711794613776,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"hjZH4vLdx7h-","outputId":"02ed2321-cf9b-486c-efb5-887dede9e00e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* This plot shows that most of the people who didn't survive were in Pclass 3.","metadata":{"id":"XL83t31yzQel"}},{"cell_type":"code","source":"plot(data, 'Survived', 'Sex')","metadata":{"executionInfo":{"elapsed":4979,"status":"ok","timestamp":1711794618740,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"6wXZcsF5zDR5","outputId":"4f36a11a-4f95-448a-eac9-f8c7dcdd7734"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* From this plot, most of people who didn't survive were strictly males.","metadata":{"id":"QFU7tSWO0Lwn"}},{"cell_type":"code","source":"plot(data, 'Survived', 'Embarked')","metadata":{"executionInfo":{"elapsed":47,"status":"ok","timestamp":1711794618740,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"XR3uMW8q0qg8","outputId":"570c1ecd-928c-4a2d-a2e1-9ab803dc3ae2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* from this plot, most of people who didn't survive were in embark 'S'.\n  \n  In other words, embark 's' took the major cause for not surviving.","metadata":{"id":"b4vVvuZ91pSw"}},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{"id":"9DUQ17VZ2UqD"}},{"cell_type":"code","source":"dc = DataCleaningClass()","metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1711794618740,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"XNUoJVry3IEq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Drop Features :","metadata":{"id":"w7kAf06A2Zuv"}},{"cell_type":"code","source":"features = ['PassengerId', 'Name','Cabin']\ndata = dc.columns_drop(data, features)\ndata.head()","metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1711794618740,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"wNyGoEAR1gQF","outputId":"5f1d9d87-e09b-44de-c860-da5a3b9d18c6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Fill NaN","metadata":{"id":"zpnUIYuBwrSv"}},{"cell_type":"code","source":"data = dc.columns_fillna(data)\nplot_missing(data)","metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1711794618740,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"Oqkr1d6_3ZS9","outputId":"175ca1b0-0d5d-4afd-ef51-5e9269476334"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Check for Duplicates","metadata":{"id":"UkLP33xYxYxv"}},{"cell_type":"code","source":"data.duplicated().sum()","metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1711794618740,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"8Zmed43CxN5s","outputId":"afec6db4-b18c-4f35-ad70-297597f1be82"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.drop_duplicates()\ndata.duplicated().sum()","metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1711794618740,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"cLLxg296xhNq","outputId":"80b30295-8fe4-4220-d9d2-f0aa9ad36ab8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Handle Outliers using IQR","metadata":{"id":"0IY33I10ydFY"}},{"cell_type":"code","source":"data.info()","metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1711794618740,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"5E_ZckGmyyJ-","outputId":"c294c325-b5ad-419a-ad70-d0875fe438bd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = dc.columns_outlier(data)\ndata.info()","metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1711794618740,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"CEoIbwMAx1w-","outputId":"97fcd8ba-34be-4e6f-a05a-d72171520f3d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Handle Skewness\n-- using log transformation for right skewed features\n\n-- using square transformation for left skewed features","metadata":{"id":"g1DEoGwn2Pez"}},{"cell_type":"code","source":"# split data to numerical and object\nnumerical_data, object_data, cat_cols, cont_cols = dc.split_data(data)\ny = data['Survived']","metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1711794618740,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"oDsAvPyn4RLU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerical_data.skew().sort_values(ascending=False)","metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1711794618740,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"8YGL-bkBy2K6","outputId":"28f0eb79-a1b1-4a65-f164-9029a1c24f41"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[numerical_data.columns] = dc.columns_transformation(numerical_data)","metadata":{"executionInfo":{"elapsed":5699,"status":"ok","timestamp":1711794659466,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"7Kq4MA3c2fW0","outputId":"0d4cccfa-c223-407e-e981-f620825295ad"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerical_data.skew().sort_values(ascending=False)","metadata":{"executionInfo":{"elapsed":266,"status":"ok","timestamp":1711794696311,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"4FAxN77C2sFH","outputId":"2ac1cf59-4f3b-444a-96b0-d0ef93a4a5eb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Encoding\n-- using label encoder","metadata":{"id":"JuDDsHeT3pI7"}},{"cell_type":"code","source":"# refresh the sub data after applying some changes\nnumerical_data, object_data, cat_cols, cont_cols = dc.split_data(data)","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711794815313,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"heZGrBsS3H8-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[object_data.columns] = dc.columns_lencoder(object_data)\ndata.head()","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1711794962968,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"LQVnHYdC6_2V","outputId":"1e7a3390-781d-40b3-cbae-bdd868647add"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"executionInfo":{"elapsed":253,"status":"ok","timestamp":1711794979812,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"HjrnDjbk7j98","outputId":"c8f3c08d-a61d-46de-8647-128acd740aae"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Train - Test Split","metadata":{"id":"ebIRqbCB7qmd"}},{"cell_type":"code","source":"X = data.drop(['Survived'],axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nprint(f'X_train shape: {X_train.shape}')\nprint(f'X_test shape: {X_test.shape}')\nprint(f'y_train shape: {y_train.shape}')\nprint(f'y_test shape: {y_test.shape}')","metadata":{"executionInfo":{"elapsed":248,"status":"ok","timestamp":1711795697900,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"-QxWWLNV7n_s","outputId":"f84cb483-1b9a-4634-edd6-10c83ef5f013"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Features Scaling\n-- using robust scaler","metadata":{"id":"86SgQtiA-oTf"}},{"cell_type":"code","source":"rs = RobustScaler()\nX_train = rs.fit_transform(X_train)\nX_test = rs.transform(X_test)\n\n","metadata":{"executionInfo":{"elapsed":319,"status":"ok","timestamp":1711796016240,"user":{"displayName":"Mennatullah Eisawy","userId":"13323608844808944812"},"user_tz":-120},"id":"vHvs6CxZ88dm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Models","metadata":{"id":"f-55l2NvQywt"}},{"cell_type":"markdown","source":"#### Logistic Regression","metadata":{}},{"cell_type":"code","source":"# Prepare a dataframe to save the models' accuracies in it\nresults = pd.DataFrame(columns=['Model', 'Train_Accuracy', 'Test_Accuracy'])\nresults","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LogisticRegression()\nmodel.fit(X_train,y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)\ntr_acc = model.score(X_train, y_train)\nte_acc = accuracy_score(y_pred, y_test)\n\nprint(tr_acc)\nprint(te_acc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = str(model).split('(')[0]\nnew_row = pd.DataFrame([[model_name, tr_acc, te_acc]], columns=results.columns)\nresults = pd.concat([results, new_row], ignore_index=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_conf_matrix(y_test, y_pred):\n    plt.figure(figsize=(5,5))\n    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='0.00f', xticklabels=['Didn\\'t_Survive','Survived'], yticklabels=['Didn\\'t_Survive','Survived'], linewidths=0.2, cbar=False)\n    plt.title(f'Test Data Confusion Matrix of {model_name}')\n    plt.xlabel('Predicted Labels')\n    plt.ylabel('Actual Labels')\n    plt.tight_layout()\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_conf_matrix(y_test, y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### XGBoost Classifier","metadata":{}},{"cell_type":"code","source":"model = XGBClassifier(n_estimators=550, learning_rate=0.001, random_state=42)\nmodel.fit(X_train,y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)\ntr_acc = model.score(X_train, y_train)\nte_acc = accuracy_score(y_pred, y_test)\n\nprint(tr_acc)\nprint(te_acc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = str(model).split('(')[0]\nnew_row = pd.DataFrame([[model_name, tr_acc, te_acc]], columns=results.columns)\nresults = pd.concat([results, new_row], ignore_index=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_conf_matrix(y_test, y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Naive Bayes Classifier","metadata":{}},{"cell_type":"code","source":"model = LGBMClassifier(n_estimators=2000, learning_rate=0.001, random_state=42)\nmodel.fit(X_train,y_train)","metadata":{"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)\ntr_acc = model.score(X_train, y_train)\nte_acc = accuracy_score(y_pred, y_test)\n\nprint(tr_acc)\nprint(te_acc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = str(model).split('(')[0]\nnew_row = pd.DataFrame([[model_name, tr_acc, te_acc]], columns=results.columns)\nresults = pd.concat([results, new_row], ignore_index=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_conf_matrix(y_test, y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Support Vector Classifier","metadata":{}},{"cell_type":"code","source":"model = SVC(C=0.5, random_state=42)\nmodel.fit(X_train,y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)\ntr_acc = model.score(X_train, y_train)\nte_acc = accuracy_score(y_pred, y_test)\n\nprint(tr_acc)\nprint(te_acc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = str(model).split('(')[0]\nnew_row = pd.DataFrame([[model_name, tr_acc, te_acc]], columns=results.columns)\nresults = pd.concat([results, new_row], ignore_index=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_conf_matrix(y_test, y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prepare the submission file","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('/Users/menna/Desktop/Amit/Data Science/Titanic ML.csv')\ntest = test.set_index('PassengerId')\n# test.shape\ntest.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfeatures = ['Name','Cabin']\ntest = dc.columns_drop(test, features)\ntest = dc.columns_fillna(test)\n# test = test.drop_duplicates()\n# test = dc.columns_outlier(test)\nnumerical_data, object_data, cat_cols, cont_cols = dc.split_data(test)\ntest[numerical_data.columns] = dc.columns_transformation(numerical_data)\nnumerical_data, object_data, cat_cols, cont_cols = dc.split_data(test)\ntest[object_data.columns] = dc.columns_lencoder(object_data)\ntest_scaled = rs.transform(test)","metadata":{"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using lgbm model\ny_pred = model.predict(test_scaled)\ny_pred","metadata":{"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'PassengerId': test.index, 'Survived': y_pred})\nsubmission.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}